{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import enable_eager_execution\n",
    "enable_eager_execution()\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "y_true = np.array([[1], [2]], dtype=np.float32)\n",
    "y_pred = np.array([[3], [5]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom loss function in the keras API should take as parameters a list of \"observed values\" and a list of \"predicted values\". The predicted values are outputs of the neural network and could be a list of predicted distributions, or a list of the distributions' means. The loss function should then return a list of loss values, one for each example, as described in the [API](https://keras.io/losses/): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=226, shape=(2,), dtype=float32, numpy=array([4., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the loss function returns a loss FOR EACH EXAMPLE! This is because `K.mean` in the definition of the above function is called with the parameter `axis=-1`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These individual loss values should be negative log likelihoods because the final loss used in training is obtained by averaging the individual losses, which would transform those individual losses into the negative log likelihood of the entire data set (divided by the number of examples), e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=278, shape=(), dtype=float32, numpy=6.5>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "mse(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look [here](https://github.com/tensorflow/tensorflow/blob/6612da89516247503f03ef76e974b51a434fb52e/tensorflow/python/keras/losses.py#L91-L92) to see one example in the source code where that averaging is implemented. Note that the averaging is implemented elsewhere when a callable `f` is provided to `model.compile(loss=f, ...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
